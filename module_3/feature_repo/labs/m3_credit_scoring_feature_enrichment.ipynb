{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8269a552-64b2-4b35-9b11-8f9e2b762e4c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Credit scoring model training and inference using Feast feature store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4874a0a-d69e-4e6d-b8ff-beaf42981f18",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# System imports\n",
    "from datetime import timedelta\n",
    "\n",
    "# 3rd party imports\n",
    "import category_encoders as ce\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from feast import  (Entity,\n",
    "                    FeatureService,\n",
    "                    FeatureStore,\n",
    "                    FeatureView,\n",
    "                    Field,\n",
    "                    FileSource,\n",
    "                    ValueType)\n",
    "from feast.types import Int64, String\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58e7fd4-378b-4835-84c2-43f6c97a0546",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Functions definitions\n",
    "def get_data_from_file(file: str) -> pd.DataFrame:\n",
    "    df = pd.read_parquet(file)\n",
    "    return df\n",
    "\n",
    "def show_df_size(df: pd.DataFrame, df_name: str) -> None:\n",
    "    print(f\"{df_name} df size: {df.shape[0]:,d} rows, {df.shape[1]:,d} columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22aabd-126f-4fd0-b5c6-122f76d0fd93",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define source data files paths\n",
    "ZIPCODE_TABLE = \"../data/zipcode_table.parquet\"\n",
    "CREDIT_HISTORY_TABLE=\"../data/credit_history.parquet\"\n",
    "LOANS_TABLE = \"../data/loan_table.parquet\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3d9bc0-b31f-4097-968c-a7d2c72bf857",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 1: Data exploration (only using local files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c8f6ba-0a6a-4a10-9e91-a137f334a9f4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get economy-wise geographical info.\n",
    "zip_df = get_data_from_file(ZIPCODE_TABLE)\n",
    "show_df_size(zip_df, \"Zip\")\n",
    "display(zip_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce6e0f0-a481-4fe7-bc70-0998b4bcdf1a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get credit-related data\n",
    "credit_df = get_data_from_file(CREDIT_HISTORY_TABLE)\n",
    "show_df_size(credit_df, \"Credit\")\n",
    "display(credit_df.sort_values(by='event_timestamp', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de1dbe-6653-445f-b0c3-5171b56eafed",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 2: Creating the feature repo and the online store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6601054-2cbd-44d0-af6e-7ec686b6f29b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Set the feature store repo path\n",
    "FEAST_REPO = \"../../feature_repo/\"\n",
    "repo_path = Path(FEAST_REPO)\n",
    "fs = FeatureStore(repo_path=repo_path) # a FeatureStore object is used to define, create, and retrieve features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a435c24-04e2-46ba-818e-fb6705923539",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the 'zipcode' and 'dob_ssn' (date-of-birth_social-sec-number) entities.\n",
    "\n",
    "An entity is a collection of semantically related features. Users define entities to map to the domain of their use case. In this case. the zip code and the dob_ssn wiil identify the requestor of a loan. We want to build a model that helps decide whether the loan should be granted or denied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f36f06-cbd4-4925-a2b3-1ca7770782d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "zipcode = Entity(\n",
    "    name=\"zipcode\",\n",
    "    value_type=Int64,\n",
    "    description=\"Zipcode for the loan origin\"\n",
    ")\n",
    "\n",
    "dob_ssn = Entity(\n",
    "    name=\"dob_ssn\",\n",
    "    value_type=String,\n",
    "    description=\"Date of birth and last four digits of social security number\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820a23a-9378-4070-99c7-2bc76b8c4c82",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the FeatureViews and FeatureService\n",
    "\n",
    "A feature view is an object that represents a logical group of time-series feature data as it is found in a data source. Feature views consist of zero or more entities, one or more features, and a data source. Feature views allow Feast to model your existing feature data in a consistent way in both an offline (training) and online (serving) environment. Feature views generally contain features that are properties of a specific object, in which case that object is defined as an entity and included in the feature view. If the features are not related to a specific object, the feature view might not have entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261f7515-d62c-43d6-84db-3ea6bfca10ce",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "Create Feat's FileSource objects:\n",
    "- Notice that only Parquet files are supported by FileSource\n",
    "'''\n",
    "\n",
    "zipcode_batch_source = FileSource(\n",
    "    path=ZIPCODE_TABLE,\n",
    "    timestamp_field=\"event_timestamp\",\n",
    "\n",
    "    created_timestamp_column=\"created_timestamp\" \n",
    ")\n",
    "\n",
    "\n",
    "credit_history_source = FileSource(\n",
    "    path=CREDIT_HISTORY_TABLE,\n",
    "    timestamp_field=\"event_timestamp\",\n",
    "    created_timestamp_column=\"created_timestamp\"\n",
    ")\n",
    "\n",
    "'''\n",
    "Create the FeatureView objects, one per each FileSource\n",
    "'''\n",
    "zipcode_features = FeatureView(\n",
    "    name=\"zipcode_features\",\n",
    "    entities=[\"zipcode\"], # entity defined by Feast.Entity\n",
    "    ttl=timedelta(days=3650), # time to live\n",
    "    schema=[\n",
    "        Field(name=\"city\", dtype=String),\n",
    "        Field(name=\"state\", dtype=String),\n",
    "        Field(name=\"location_type\", dtype=String),\n",
    "        Field(name=\"tax_returns_filed\", dtype=Int64),\n",
    "        Field(name=\"population\", dtype=Int64),\n",
    "        Field(name=\"total_wages\", dtype=Int64),\n",
    "    ],\n",
    "    source=zipcode_batch_source,\n",
    "    online=True,\n",
    ")\n",
    "\n",
    "credit_history = FeatureView(\n",
    "    name=\"credit_history\",\n",
    "    entities=[\"dob_ssn\"], # entity defined by Feast.Entity\n",
    "    ttl=timedelta(days=800), # time to live\n",
    "    schema=[\n",
    "        Field(name=\"credit_card_due\", dtype=Int64),\n",
    "        Field(name=\"mortgage_due\", dtype=Int64),\n",
    "        Field(name=\"student_loan_due\", dtype=Int64),\n",
    "        Field(name=\"vehicle_loan_due\", dtype=Int64),\n",
    "        Field(name=\"hard_pulls\", dtype=Int64),\n",
    "        Field(name=\"missed_payments_2y\", dtype=Int64),\n",
    "        Field(name=\"missed_payments_1y\", dtype=Int64),\n",
    "        Field(name=\"missed_payments_6m\", dtype=Int64),\n",
    "        Field(name=\"bankruptcies\", dtype=Int64),\n",
    "    ],\n",
    "    source=credit_history_source,\n",
    "    online=True\n",
    ")\n",
    "\n",
    "'''\n",
    "Create the feature service: A feature service defines a logical group of features from one or more feature views.\n",
    "This group of features can be retrieved together during training or serving.\n",
    "'''\n",
    "model_features_svc = FeatureService(\n",
    "    name=\"model_features_svc\",\n",
    "    features=[zipcode_features, credit_history],\n",
    "    tags={\"Description\": \"Used for training a XGBoost Logistic Regression model\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e82521-21ae-4005-8a7a-ea741ffe9946",
   "metadata": {
    "tags": [],
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Register objects to metadata store and update related infrastructure.\n",
    "\n",
    "The apply method registers one or more definitions (e.g., Entity, FeatureView) and registers or updates these\n",
    "objects in the Feast registry. Once the apply method has updated the infrastructure (e.g., create tables in\n",
    "an online store), it will commit the updated registry. All operations are idempotent, meaning they can safely\n",
    "be rerun.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "422decbe-63e0-4f22-be72-18cd16bc2854",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Apply feature store definitions\n",
    "fs.apply([zipcode, dob_ssn, # Entities\n",
    "          zipcode_features, credit_history, # FeatureViews\n",
    "          model_features_svc # FeatureService\n",
    "         ])\n",
    "\n",
    "# Display feature services, feature views and feature names just registered\n",
    "for feature_svc in fs.list_feature_services():\n",
    "    print(f\"Feature service name: {feature_svc.name}\")\n",
    "    for projection in feature_svc.feature_view_projections:\n",
    "        print(f\"\\tFeature view: {projection.name}\")\n",
    "        for feat in projection.features:\n",
    "            print(f\"\\t\\tFeature: {feat.name}, type: {feat.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d588-749e-4597-8770-c0d6f222c8c5",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Load (materialize) data from the offline store into the online store.\n",
    "\n",
    "This method loads feature data in the specified interval from either\n",
    "the specified feature views, or all feature views if none are specified,\n",
    "into the online store where it is available for online serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0af237-afc1-45f0-bfcd-e42fbfbae7a5",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "start_date = datetime(2017, 1, 1, 0, 0, 0)\n",
    "end_date = datetime(2021, 9, 1,  0, 0, 0)\n",
    "fs.materialize(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "890cebd0-89d7-46f3-8eae-4c14418ab588",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 3: Use feature defintions augmented with a \"loans\" data table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54f20bc-14f2-4c13-8d74-faaacb563edf",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Recovering features from the feature service\n",
    "feat_svc = fs.list_feature_services()[-1] # get the last feature service in the list\n",
    "feast_features = []\n",
    "for view_proj in feat_svc.feature_view_projections: \n",
    "    #print(view_proj.name)\n",
    "    for feature in view_proj.features:\n",
    "        #print(f\"\\t{feature.name}\")\n",
    "        feast_features.append(f\"{view_proj.name}:{feature.name}\")\n",
    "pprint(feast_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848cc5fd-44f1-4cf0-bafa-8d5b63292c4d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get a couple of vector features from the online store\n",
    "zipcodes_dob_ssns = [(8089, \"19600724_9887\"), (69033, \"19960703_3449\")]\n",
    "for zipcode, dob_ssn in zipcodes_dob_ssns:\n",
    "    print(f\"Feature vector for zipcode {zipcode} and dob_ssn {dob_ssn}:\")\n",
    "    data = fs.get_online_features(\n",
    "            entity_rows=[{\"zipcode\": zipcode, \"dob_ssn\": dob_ssn}],\n",
    "            features=feast_features).to_dict()\n",
    "    display(pd.DataFrame.from_dict({key:data[key] for key in data}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe772798-ea66-4ee3-a059-33b211b24e01",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get the Loans table to be used to train the model\n",
    "loans_df = pd.read_parquet(LOANS_TABLE)\n",
    "print(f\"Loans df size: {loans_df.shape[0]} rows, {loans_df.shape[1]} cols\")\n",
    "display(loans_df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c15002-b5cd-4acd-a3c6-41ebb5ff6275",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(loans_df[loans_df.dob_ssn == '19600724_9887'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26107cd9-d09f-4937-b184-4fc98a03d4d0",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "display(loans_df[loans_df.dob_ssn == '19960703_3449'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99645dc9-420d-4cd1-853b-103245f1c98d",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### get_historical_features(). Enrich an entity dataframe with historical feature values for either training or batch scoring.\n",
    "\n",
    "This method joins historical feature data from one or more feature views to an entity dataframe by using a time\n",
    "travel join. Each feature view is joined to the entity dataframe using all entities configured for the respective feature\n",
    "view. All configured entities must be available in the entity dataframe. Therefore, the entity dataframe must\n",
    "contain all entities found in all feature views, but the individual feature views can have different entities.\n",
    "\n",
    "Time travel is based on the configured TTL for each feature view. A shorter TTL will limit the\n",
    "amount of scanning that will be done in order to find feature data for a specific entity key. \n",
    "\n",
    "->> Setting a short TTL may result in null values being returned.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06139d23-872f-4ecc-954a-4767631e8ea9",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "train_df = fs.get_historical_features(entity_df=loans_df, features=feast_features).to_df()\n",
    "print(f\"Training df size: {train_df.shape[0]} rows, {train_df.shape[1]} cols\")\n",
    "display(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c967f653-8f64-49d6-97a3-14b019c79283",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 4. Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4d772a-dec1-471f-bace-c0e9ae91b465",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b272b3-3926-4d22-8235-f83ce829174a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define categorical columns and the list of columns to remove for modeling purposes\n",
    "categorical_features = [\n",
    "    \"person_home_ownership\",\n",
    "    \"loan_intent\",\n",
    "]\n",
    "\n",
    "columns_to_drop = [\n",
    "    \"city\",\n",
    "    \"state\",\n",
    "    \"event_timestamp\",\n",
    "    \"created_timestamp__\",\n",
    "    \"loan_id\",\n",
    "    \"loan_status\",\n",
    "    \"dob_ssn\",\n",
    "    \"zipcode\",\n",
    "    \"location_type\",\n",
    "]\n",
    "train_y = train_df.loan_status\n",
    "train_X = train_df.drop(columns=columns_to_drop) # drop columns with no modeling role\n",
    "train_X = train_X.reindex(sorted(train_X.columns), axis=1) # sort columns to keep the same order\n",
    "for col in categorical_features: # \"category\" dtype of categorical columns\n",
    "    train_X[col] = train_X[col].astype(\"category\")\n",
    "one_hot_encoder = ce.OneHotEncoder(cols=categorical_features) # create a categorical values transformer\n",
    "train_X = one_hot_encoder.fit_transform(train_X) # Fit and apply a transformer to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5c83a1-f6f7-48a8-b167-4692e9bd1bde",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"train_X df size: {train_X.shape[0]} rows, {train_X.shape[1]} cols\")\n",
    "train_X.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373e3bd2-e5fe-4717-bcef-3760469efcd8",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Define training and test matrices in XGBoost format\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_X, train_y, random_state=42) # split the dataset\n",
    "dtrain = xgb.DMatrix(data=X_train, label=y_train) # DMatrix for XGBoost training\n",
    "dtest = xgb.DMatrix(data=X_test, label=y_test) # DMatrix for XGBoost test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44edd2b1-7c8e-476d-8048-3ff02c3ac621",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Train an XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb24a37-b1e8-4cbb-b7a7-6919e7801fa4",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Set xgboost params\n",
    "param = {\n",
    "    'booster' : 'dart',\n",
    "    'learning_rate': 0.1,\n",
    "    'verbosity': 1,\n",
    "    'max_depth': 7,  # the maximum depth of each tree\n",
    "    'objective': 'binary:hinge',  # error evaluation for binary class training\n",
    "    'eval_metric': ['logloss', 'error'],\n",
    "    'rate_drop': 0.1,\n",
    "    'skip_drop': 0.5,\n",
    "}\n",
    "num_rounds = 100  # Set the number of training iterations\n",
    "model = xgb.train(param, dtrain, num_rounds) # Train model\n",
    "preds = model.predict(dtest) # Test model\n",
    "print(f\"ROC-AUC score: {roc_auc_score(y_test, preds, average='weighted')}\") # Evaluate model's performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c41879bf-67ef-4d43-a819-766c7e772db9",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Section 5. Make predictions using the online feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7f56f7-1895-4f40-bdff-0ec53003628d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using loan id numbers, grab the zipcode and dob_ssn entities to make a prediction\n",
    "infer_vectors = []\n",
    "for loan_id in [28821, 38637, 10000]:\n",
    "    loan_record = loans_df[loans_df.loan_id == loan_id]\n",
    "    infer_vectors.append(loan_record)\n",
    "    display(loan_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702912a0-889c-4189-8324-869780b23364",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for vec in infer_vectors:\n",
    "    vec = vec.iloc[0].to_dict()\n",
    "    print(f\"\\n>>>> Build feature vector for loan_id {vec['loan_id']}\")\n",
    "    zipcode=vec['zipcode']\n",
    "    dob_ssn=vec['dob_ssn']\n",
    "\n",
    "    # Get the feature vector from the online store to enrich the inference vector\n",
    "    feat_vec = fs.get_online_features(entity_rows=[{\"zipcode\": vec['zipcode'], \"dob_ssn\": vec['dob_ssn']}],\n",
    "                          features=feast_features).to_dict()\n",
    "    vec.update(feat_vec)\n",
    "    inf_vec = pd.DataFrame.from_dict(vec)\n",
    "    display(inf_vec) # show the complete inference vector\n",
    "    \n",
    "    # Apply transformations to inference vector\n",
    "    for col in categorical_features: # \"category\" dtype of categorical columns\n",
    "        inf_vec[col] = inf_vec[col].astype(\"category\")\n",
    "    to_drop = columns_to_drop.copy()\n",
    "    to_drop = list(map(lambda x: x.replace('created_timestamp__', 'created_timestamp'), to_drop)) # Fix a weird column rename made by Feast\n",
    "    inf_vec = inf_vec.drop(columns=to_drop) # Drop columns with no modeling role\n",
    "    inf_vec = inf_vec.reindex(sorted(inf_vec.columns), axis=1) # Sort columns alphabetically for consisting ordering\n",
    "    inf_vec = one_hot_encoder.transform(inf_vec) # Apply the transformer\n",
    "    data = xgb.DMatrix(inf_vec) # convert Pandas to DMatrix\n",
    "    \n",
    "    prediction = model.predict(data) # Make predictions\n",
    "    print(f\"\\nPrediction for loan_id {vec['loan_id']}: {'approved' if prediction else 'denied'} <<<< \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40485e03-353e-4ba0-8f35-e80aeede7c0e",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "feast_ws",
   "language": "python",
   "name": "feast_workshop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}